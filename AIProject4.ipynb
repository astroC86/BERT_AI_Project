{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIProject4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/astroC86/BERT_AI_Project/blob/main/AIProject4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "ZPDpvWrS4gXY",
        "outputId": "82e05cc1-2db2-40e2-c6ae-891d86972fb9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-714b20e0-60eb-4c97-8b51-63b8c5110e9f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-714b20e0-60eb-4c97-8b51-63b8c5110e9f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "#https://towardsdatascience.com/downloading-datasets-into-google-drive-via-google-colab-bcb1b30b0166\n",
        "# Link for how to download kaggle data to colab\n",
        "\n",
        "from google.colab import files\n",
        "t = files.upload()\n",
        "t = None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5bdmRWV8uiL",
        "outputId": "19aee270-fcf3-47eb-c35e-3f284ffebaa2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WI4w3NJb81k4",
        "outputId": "d6a36b24-3c78-464a-b4c1-a179cf813e97"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading imdb-dataset-of-50k-movie-reviews.zip to /content\n",
            " 19% 5.00M/25.7M [00:00<00:00, 35.5MB/s]\n",
            "100% 25.7M/25.7M [00:00<00:00, 102MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip imdb-dataset-of-50k-movie-reviews.zip  #unzip data "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6OqTeBb98qJ",
        "outputId": "1e0869a9-65c6-4a58-b75f-9e39721be045"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  imdb-dataset-of-50k-movie-reviews.zip\n",
            "  inflating: IMDB Dataset.csv        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas            as pd"
      ],
      "metadata": {
        "id": "MjySKs1FZ3Xh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df        = pd.read_csv(\"IMDB Dataset.csv\")\n",
        "print(\"First 10 rows of the DataFrame:\")\n",
        "#print(df)\n",
        "\n",
        "df.groupby(['sentiment']).size().plot.bar()\n",
        "df.describe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "ZqI9a6n2KOs7",
        "outputId": "4ab245f5-f89e-4398-9f14-f82684c8955c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 rows of the DataFrame:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of                                                   review sentiment\n",
              "0      One of the other reviewers has mentioned that ...  positive\n",
              "1      A wonderful little production. <br /><br />The...  positive\n",
              "2      I thought this was a wonderful way to spend ti...  positive\n",
              "3      Basically there's a family where a little boy ...  negative\n",
              "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "...                                                  ...       ...\n",
              "49995  I thought this movie did a down right good job...  positive\n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
              "49997  I am a Catholic taught in parochial elementary...  negative\n",
              "49998  I'm going to have to disagree with the previou...  negative\n",
              "49999  No one expects the Star Trek movies to be high...  negative\n",
              "\n",
              "[50000 rows x 2 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_org = df.drop([\"sentiment\"], axis=\"columns\")\n",
        "y_org = df.drop([\"review\"], axis=\"columns\").replace({\"positive\": 1, \"negative\": 0})\n",
        "\n",
        "print('review')\n",
        "print(x_org)\n",
        "\n",
        "print('sentiment')\n",
        "print(y_org)\n",
        "\n",
        "print(\"Original training dataset shape:\")\n",
        "print(y_org.squeeze().value_counts())\n",
        "\n",
        "print(\"\\n\\n data is split equaly from the get go\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txzSXwcIVA8N",
        "outputId": "994a9e55-e1b5-40c7-a877-dd9d919f48fb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "review\n",
            "                                                  review\n",
            "0      One of the other reviewers has mentioned that ...\n",
            "1      A wonderful little production. <br /><br />The...\n",
            "2      I thought this was a wonderful way to spend ti...\n",
            "3      Basically there's a family where a little boy ...\n",
            "4      Petter Mattei's \"Love in the Time of Money\" is...\n",
            "...                                                  ...\n",
            "49995  I thought this movie did a down right good job...\n",
            "49996  Bad plot, bad dialogue, bad acting, idiotic di...\n",
            "49997  I am a Catholic taught in parochial elementary...\n",
            "49998  I'm going to have to disagree with the previou...\n",
            "49999  No one expects the Star Trek movies to be high...\n",
            "\n",
            "[50000 rows x 1 columns]\n",
            "sentiment\n",
            "       sentiment\n",
            "0              1\n",
            "1              1\n",
            "2              1\n",
            "3              0\n",
            "4              1\n",
            "...          ...\n",
            "49995          1\n",
            "49996          0\n",
            "49997          0\n",
            "49998          0\n",
            "49999          0\n",
            "\n",
            "[50000 rows x 1 columns]\n",
            "Original training dataset shape:\n",
            "1    25000\n",
            "0    25000\n",
            "Name: sentiment, dtype: int64\n",
            "\n",
            "\n",
            " data is split equaly from the get go\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_testValidate, y_train, y_testValidate = train_test_split(x_org, y_org,\n",
        "                                                    test_size=0.30,\n",
        "                                                    random_state=0,\n",
        "                                                    stratify=y_org)\n",
        "\n",
        "x_validate, x_test, y_validate, y_test          = train_test_split(x_testValidate, y_testValidate,\n",
        "                                                    test_size=(2/3),\n",
        "                                                    random_state=0,\n",
        "                                                    stratify=y_testValidate)\n",
        "\n",
        "print(\"Positive-Negative split for training\")\n",
        "print(y_train.squeeze().value_counts())\n",
        "\n",
        "print(\"\\n\\nPositive-Negative split for testing\")\n",
        "print(y_test.squeeze().value_counts())\n",
        "\n",
        "print(\"\\n\\nPositive-Negative split for validation\")\n",
        "print(y_validate.squeeze().value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYb06ZBtW0mp",
        "outputId": "890f832f-8f5a-4954-b929-a0f4bd3d3d36"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive-Negative split for training\n",
            "1    17500\n",
            "0    17500\n",
            "Name: sentiment, dtype: int64\n",
            "\n",
            "\n",
            "Positive-Negative split for testing\n",
            "1    5000\n",
            "0    5000\n",
            "Name: sentiment, dtype: int64\n",
            "\n",
            "\n",
            "Positive-Negative split for validation\n",
            "1    2500\n",
            "0    2500\n",
            "Name: sentiment, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HqrVnpsooib7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from typing_extensions import final\n",
        "# as per recommendation from @freylis, compile once only\n",
        "CLEANR = re.compile('<.*?>') \n",
        "\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def preprocess(text):\n",
        "  texts = re.sub(CLEANR, ' ', text) # reomving html entities\n",
        "  texts = \"\".join([char for char in texts if char not in string.punctuation]) # removing punctiuation\n",
        "  texts = texts.lower() #lowering \n",
        "  texts = texts.split(' ')\n",
        "  texts = [word for word in texts if word not in stop_words] #removing stopwords\n",
        "  texts = [lemmatizer.lemmatize(word=word,pos='v') for word in texts] #lematizing\n",
        "  texts = ' '.join(texts)\n",
        "  return texts"
      ],
      "metadata": {
        "id": "ZmvZSkz7yWVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d401b05f-821c-4364-8704-30576291f9d5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pp_x_train    = pd.DataFrame({'review': x_train['review'].apply(preprocess)})\n",
        "pp_y_train    = y_train\n",
        "\n",
        "pp_x_validate = pd.DataFrame({'review': x_validate['review'].apply(preprocess)})\n",
        "pp_x_test     = pd.DataFrame({'review': x_test ['review'].apply(preprocess)})\n",
        "\n",
        "pp_y_validate, pp_y_test = y_validate, y_test  "
      ],
      "metadata": {
        "id": "oz76pcKECYUm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbfLfh1cxSH5",
        "outputId": "4101007f-2252-4602-ff82-27e99bb3e4dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.16.0-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 64.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 58.9 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 50.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jrJTWX4Eg4Fq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, _x,_y):\n",
        "      self.texts     = _x\n",
        "      self.sentiment = torch.FloatTensor(_y.to_numpy())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        global tokenizer\n",
        "        try:\n",
        "          batch_texts = tokenizer(self.texts['review'][idx], \n",
        "                                  padding  = 'max_length', \n",
        "                                  max_length       = 512, \n",
        "                                  truncation       = True,\n",
        "                                  return_tensors   = \"pt\")\n",
        "        except e as Exception:\n",
        "          print(idx,self.texts['review'][idx])\n",
        "          raise e\n",
        "        \n",
        "        batch_y     = self.sentiment[idx][0]\n",
        "        return batch_texts, batch_y"
      ],
      "metadata": {
        "id": "4FEmLIDTZURw"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Hkm3bzzcygb0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Preparing BERT Model**"
      ],
      "metadata": {
        "id": "k3LWNuLZPHUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS         = 50\n",
        "BATCH_SIZE     = 1\n",
        "LEARNING_RATE  = 0.001"
      ],
      "metadata": {
        "id": "5E2O8AtTYEDZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from transformers import BertModel\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "    def __init__(self, dropout=0.5):\n",
        "        super(BertClassifier, self).__init__()\n",
        "        self.bert    = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.l1      = nn.Linear(768, 512)\n",
        "        self.l2      = nn.Linear(512, 256)\n",
        "        self.l3      = nn.Linear(256, 64)\n",
        "        self.l4      = nn.Linear(64, 1)\n",
        "        self.relu    = nn.ReLU()\n",
        "    # to reference for possible imporvement\n",
        "    #https://github.com/huggingface/transformers/issues/1328\n",
        "    def forward(self, input_id, mask):\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        x                = self.dropout(pooled_output)\n",
        "        x                = self.dropout(self.relu(self.l1(x)))\n",
        "        x                = self.dropout(self.relu(self.l2(x)))\n",
        "        x                = self.dropout(self.relu(self.l3(x)))\n",
        "        x                = self.relu(self.l4(x))\n",
        "        final_layer      = self.relu(x)\n",
        "        return final_layer"
      ],
      "metadata": {
        "id": "Z-NauMNzPSmH"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EHhkHVDFX8Gq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def train(model, x_train_data, Y_train_data, x_val_data,Y_val_data, learning_rate, epochs):\n",
        "\n",
        "    train, val = MyDataset(x_train_data,Y_train_data), MyDataset(x_val_data,Y_val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_dataloader   = torch.utils.data.DataLoader(val, batch_size=BATCH_SIZE)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device   = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    \n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "            for train_input, train_label in train_dataloader:\n",
        "\n",
        "                train_label = train_label.to(device)\n",
        "                mask        = train_input['attention_mask'].to(device)\n",
        "                input_id    = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output      = model(input_id, mask)\n",
        "                output      = torch.round(torch.sigmoid(output))\n",
        "                print(\">>>>> O: \",output,\" T: \",train_label)\n",
        "              \n",
        "                batch_loss = criterion(output, train_label)\n",
        "                total_loss_train += batch_loss.item()\n",
        "                \n",
        "                acc = (output == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "                model.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for val_input, val_label in val_dataloader:\n",
        "\n",
        "                    val_label = val_label.to(device)\n",
        "                    mask = val_input['attention_mask'].to(device)\n",
        "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                    output = model(input_id, mask)\n",
        "\n",
        "                    batch_loss = criterion(output, val_label)\n",
        "                    total_loss_val += batch_loss.item()\n",
        "                    \n",
        "                    acc = (output == train_label).sum().item()\n",
        "                    total_acc_val += acc\n",
        "            \n",
        "            print(\n",
        "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(x_train_data): .3f} \\\n",
        "                | Train Accuracy: {total_acc_train / len(x_train_data): .3f} \\\n",
        "                | Val Loss: {total_loss_val / len(x_val_data): .3f} \\\n",
        "                | Val Accuracy: {total_acc_val / len(x_val_data): .3f}')"
      ],
      "metadata": {
        "id": "5KWhRLzpa5xN"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model     = BertClassifier()\n",
        "\n",
        "train(model,pp_x_train,pp_y_train,pp_x_validate,pp_y_validate,LEARNING_RATE,EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "3IJGvJ5hX6wU",
        "outputId": "ce4bbc64-38bd-4a87-925f-4fc8684fc178"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>>> O:  tensor([[1.]], device='cuda:0', grad_fn=<RoundBackward0>)  T:  tensor([0.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-47d14fe4334a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mBertClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpp_x_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpp_y_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpp_x_validate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpp_y_validate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-b22456b3a3db>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, x_train_data, Y_train_data, x_val_data, Y_val_data, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">>>>> O: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" T: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0mtotal_loss_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    705\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([1])) must be the same as input size (torch.Size([1, 1]))"
          ]
        }
      ]
    }
  ]
}